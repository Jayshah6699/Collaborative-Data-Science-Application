{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Data Processing\n",
    "***\n",
    "Take a look here to see how I extracted features from the test data. I eventually split this up among several computers/EC2 instances since it took a surprisingly long time (somehow it took longer than processing the train data, what the heck?)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "import glob\n",
    "\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import NuSVR\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from tsfresh import select_features\n",
    "from tsfresh.utilities.dataframe_functions import impute\n",
    "from tsfresh import extract_features\n",
    "import tsfresh\n",
    "from tsfresh.feature_extraction import EfficientFCParameters\n",
    "from tsfresh.feature_extraction.settings import from_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tsfreshify(df, i):\n",
    "    rows = 150000\n",
    "    idlist = [i for n in range(rows)]\n",
    "    df['id'] = idlist\n",
    "    df.columns = ['time', 'acoustic_data', 'id']\n",
    "    cols = df.columns.tolist()\n",
    "    cols = cols[-1:] + cols[:-1]\n",
    "    df = df[cols]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#My final collection of tsfresh features to use\n",
    "smaller2 = {'acoustic_data': {'number_peaks': [{'n': 3}, {'n': 1}, {'n': 5}, {'n': 10}],\n",
    "  'change_quantiles': [{'f_agg': 'mean', 'isabs': True, 'qh': 1.0, 'ql': 0.2},\n",
    "   {'f_agg': 'mean', 'isabs': True, 'qh': 1.0, 'ql': 0.4},\n",
    "   {'f_agg': 'var', 'isabs': False, 'qh': 1.0, 'ql': 0.4}],\n",
    "  'range_count': [{'max': 1000000000000.0, 'min': 0}],\n",
    "  'number_cwt_peaks': [{'n': 1}],\n",
    "  'mean_abs_change': None,\n",
    "  'absolute_sum_of_changes': None,\n",
    "  'c3': [{'lag': 1}, {'lag': 2}],\n",
    "  'ar_coefficient': [{'k': 10, 'coeff': 4}, {'k': 10, 'coeff': 1}],\n",
    "  'partial_autocorrelation': [{'lag': 2},\n",
    "   {'lag': 8},\n",
    "   {'lag': 3},\n",
    "   {'lag': 9},\n",
    "   {'lag': 1}],\n",
    "  'quantile': [{'q': 0.1}],\n",
    "  'fft_aggregated': [{'aggtype': 'variance'}, {'aggtype': 'centroid'}],\n",
    "  'spkt_welch_density': [{'coeff': 2}],\n",
    "  'agg_linear_trend': [{'f_agg': 'min', 'chunk_len': 50, 'attr': 'intercept'},\n",
    "   {'f_agg': 'mean', 'chunk_len': 5, 'attr': 'stderr'},\n",
    "   {'f_agg': 'max', 'chunk_len': 50, 'attr': 'intercept'}],\n",
    "  'variance': None,\n",
    "  'standard_deviation': None,\n",
    "  'linear_trend': [{'attr': 'stderr'}],\n",
    "  'cid_ce': [{'normalize': True}],\n",
    "  'autocorrelation': [{'lag': 1}]}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "92"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = '../input/test'\n",
    "names = [f for f in glob.glob(path + \"**/*.csv\", recursive = True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in names:\n",
    "    tests.append(pd.read_csv(file, dtype={'acoustic_data': np.int16}).reset_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "63"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xs = [tsfreshify(test, i) for test, i in zip(tests, ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "testname = names[0][14:].split('.')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "names2 = [name[14:].split('.')[0] for name in names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, name2 in zip(names[:100], names2[:100]):\n",
    "    i += 1\n",
    "    X = tsfreshify(pd.read_csv(name, dtype={'acoustic_data': np.int16}).reset_index(),i)\n",
    "    features = testextract_features(X, column_id=\"id\", column_sort=\"time\",n_jobs=8, default_fc_parameters=smaller2['acoustic_data'])\n",
    "    with open('testfeatures/%s' % name2, 'wb') as pickle_out:\n",
    "        pickle.dump(features[-1], pickle_out)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
